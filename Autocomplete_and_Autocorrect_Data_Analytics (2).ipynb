{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x8hczSp9I17",
        "outputId": "ffc30eed-a70d-4a72-c5c5-ed02ca326285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: textdistance in /usr/local/lib/python3.11/dist-packages (4.6.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample tokens: ['asian', 'exporters', 'fear', 'damage', 'from', 'u', 's', 'japan', 'rift', 'mounting', 'trade', 'friction', 'between', 'the', 'u', 's', 'and', 'japan', 'has', 'raised']\n",
            "Total tokens: 1330383\n",
            "\n",
            "--- Autocorrect Tests ---\n",
            "hte -> he\n",
            "recieve -> recieve\n",
            "\n",
            "--- Autocomplete Tests ---\n",
            "government -> ['s', 'to', 'has', 'securities', 'officials']\n",
            "\n",
            "Phrase autocomplete for 'the government':\n",
            "['the government s', 'the government to', 'the government has', 'the government securities', 'the government officials']\n",
            "\n",
            "Enter a word or phrase (or 'exit' to stop): asain\n",
            "Autocorrect (last word): again\n",
            "Autocomplete (next word): []\n",
            "Autocomplete phrase: []\n",
            "\n",
            "Enter a word or phrase (or 'exit' to stop): officials\n",
            "Autocorrect (last word): officials\n",
            "Autocomplete (next word): ['said', 'have', 'of', 'told', 'in']\n",
            "Autocomplete phrase: ['officials said', 'officials have', 'officials of', 'officials told', 'officials in']\n",
            "\n",
            "Enter a word or phrase (or 'exit' to stop): told\n",
            "Autocorrect (last word): told\n",
            "Autocomplete (next word): ['reuters', 'the', 'a', 'reporters', 'journalists']\n",
            "Autocomplete phrase: ['told reuters', 'told the', 'told a', 'told reporters', 'told journalists']\n",
            "\n",
            "Enter a word or phrase (or 'exit' to stop): abhi\n",
            "Autocorrect (last word): abi\n",
            "Autocomplete (next word): []\n",
            "Autocomplete phrase: []\n",
            "\n",
            "Enter a word or phrase (or 'exit' to stop): told\n",
            "Autocorrect (last word): told\n",
            "Autocomplete (next word): ['reuters', 'the', 'a', 'reporters', 'journalists']\n",
            "Autocomplete phrase: ['told reuters', 'told the', 'told a', 'told reporters', 'told journalists']\n",
            "\n",
            "Enter a word or phrase (or 'exit' to stop): exit\n"
          ]
        }
      ],
      "source": [
        "# ========================================\n",
        "# Autocomplete & Autocorrect - Oasis Infobyte Task\n",
        "# Fixed Version with punkt_tab\n",
        "# ========================================\n",
        "\n",
        "# Step 1: Install required libraries\n",
        "!pip install nltk textdistanceg\n",
        "\n",
        "# Step 2: Import libraries\n",
        "import nltk\n",
        "import re\n",
        "import textdistance\n",
        "from collections import Counter, defaultdict\n",
        "from nltk.util import ngrams\n",
        "\n",
        "# Step 3: Download NLTK data (fixed)\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # <-- Fix for ValueError\n",
        "\n",
        "# Step 4: Load a sample text dataset (Reuters corpus)\n",
        "from nltk.corpus import reuters\n",
        "corpus_text = \" \".join([\" \".join(sent) for sent in reuters.sents()])\n",
        "\n",
        "# Step 5: Preprocess text\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)  # Keep only letters and spaces\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "tokens = preprocess(corpus_text)\n",
        "print(f\"Sample tokens: {tokens[:20]}\")\n",
        "print(f\"Total tokens: {len(tokens)}\")\n",
        "\n",
        "# Step 6: Build word frequency dictionary for autocorrect\n",
        "word_freq = Counter(tokens)\n",
        "\n",
        "# Step 7: Autocorrect function\n",
        "def autocorrect(word):\n",
        "    if word in word_freq:\n",
        "        return word\n",
        "    candidates = [(w, textdistance.levenshtein(word, w)) for w in word_freq.keys()]\n",
        "    candidates = sorted(candidates, key=lambda x: (x[1], -word_freq[x[0]]))\n",
        "    return candidates[0][0] if candidates else word\n",
        "\n",
        "# Step 8: Build bigram model for autocomplete\n",
        "bigram_model = defaultdict(Counter)\n",
        "for w1, w2 in ngrams(tokens, 2):\n",
        "    bigram_model[w1][w2] += 1\n",
        "\n",
        "def autocomplete(word, top_n=5):\n",
        "    if word not in bigram_model:\n",
        "        return []\n",
        "    suggestions = bigram_model[word].most_common(top_n)\n",
        "    return [w for w, _ in suggestions]\n",
        "\n",
        "# Step 9: Phrase-based autocomplete\n",
        "def autocomplete_phrase(phrase, top_n=5):\n",
        "    words = preprocess(phrase)\n",
        "    if not words:\n",
        "        return []\n",
        "    last_word = words[-1]\n",
        "    completions = autocomplete(last_word, top_n)\n",
        "    return [phrase + \" \" + c for c in completions]\n",
        "\n",
        "# Step 10: Tests\n",
        "print(\"\\n--- Autocorrect Tests ---\")\n",
        "print(\"hte ->\", autocorrect(\"hte\"))\n",
        "print(\"recieve ->\", autocorrect(\"recieve\"))\n",
        "\n",
        "print(\"\\n--- Autocomplete Tests ---\")\n",
        "print(\"government ->\", autocomplete(\"government\"))\n",
        "print(\"\\nPhrase autocomplete for 'the government':\")\n",
        "print(autocomplete_phrase(\"the government\"))\n",
        "\n",
        "# Step 11: Interactive Mode\n",
        "while True:\n",
        "    user_input = input(\"\\nEnter a word or phrase (or 'exit' to stop): \").lower()\n",
        "    if user_input == 'exit':\n",
        "        break\n",
        "    print(\"Autocorrect (last word):\", autocorrect(user_input.split()[-1]))\n",
        "    print(\"Autocomplete (next word):\", autocomplete(user_input.split()[-1]))\n",
        "    print(\"Autocomplete phrase:\", autocomplete_phrase(user_input))\n"
      ]
    }
  ]
}